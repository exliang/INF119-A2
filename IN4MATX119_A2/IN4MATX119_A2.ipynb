{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a2d39d6",
   "metadata": {},
   "source": [
    "Team Members:\n",
    "- Emily Liang 79453973\n",
    "- \n",
    "- \n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38d5258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "%pip install gradio unstructured sentence-transformers\n",
    "%pip install google.generativeai     # for using local IDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3e3fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# print(sys.executable)\n",
    "!{sys.executable} -m pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee59c4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries (RERUN THIS CELL IF NEEDED)\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "import google.generativeai as genai\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7385ca62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.generativeai import types #(RERUN THIS CELL IF NEEDED)\n",
    "import os\n",
    "\n",
    "# For local environment, directly put your API key here\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "genai.configure(api_key=api_key)\n",
    "model = genai.GenerativeModel(model_name=\"gemini-2.5-flash-lite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0d3561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 1: Transcribing handwritten Python code into a code snippet - Emily\n",
    "\n",
    "import re\n",
    "\n",
    "# Goal: take an img including handwritten python code, feed it into LLM, & return the python code as text\n",
    "def transcribe_image_code(image_file: Image.Image) -> str:\n",
    "    \"\"\"\n",
    "    Step 1: Transcribes code from the input image using a multimodal LLM.\n",
    "\n",
    "    Parameters:\n",
    "        image_file (Image.Image): The uploaded image containing handwritten code.\n",
    "\n",
    "    Returns:\n",
    "        str: The transcribed code as a string.\n",
    "    \"\"\"\n",
    "    \n",
    "    # prompt given to the LLM to transcribe the code from the image\n",
    "    prompt = \"\"\"Given the following image containing handwritten Python code, transcribe the code accurately into a text format and output it.\"\"\"\n",
    "\n",
    "    # call the LLM with the prompt and image\n",
    "    output = model.generate_content([prompt, image_file])\n",
    "\n",
    "    # extract the transcribed code from the LLM output & ensure it has text\n",
    "    code = output.text if output and output.text else \"\"\n",
    "\n",
    "    # remove any markdown formatting (like ```python ... ```) from the transcribed code\n",
    "    code = re.sub(r\"```(?:python)?\\n?\", \"\", code) \n",
    "    code = code.replace(\"```\", \"\")\n",
    "\n",
    "    # return the cleaned code as a string\n",
    "    return code.strip()\n",
    "\n",
    "# Testing the function with an example image\n",
    "img_path = \"code_images_example/code_image_07.jpg\"\n",
    "image = Image.open(img_path)\n",
    "print(transcribe_image_code(image))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77e42b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 2: Running static analysis and explaining bugs (if any) in natural language\n",
    "\n",
    "def analyze_code(code_block: str):\n",
    "    \"\"\"\n",
    "    Step 2: Performs static analysis on the transcribed code.\n",
    "\n",
    "    Parameters:\n",
    "        code_block (str): The transcribed code snippet.\n",
    "\n",
    "    Returns:\n",
    "        (1) The analysis text explaining bugs, improvements, or efficiency suggestions.\n",
    "        (2) The refined version of the code snippet with the suggested fixes and enhancements.\n",
    "    \"\"\"\n",
    "\n",
    "    if not code_block:\n",
    "        raise gr.Error(\"Please provide a valid code snippet.\")\n",
    "\n",
    "    try:\n",
    "        model = genai.GenerativeModel(MODEL_ID)\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "        You are an expert Python developer and code reviewer. Analyze the following code.\n",
    "\n",
    "        ## TODO: Modify the prompt to inference LLM on the code snippet.\n",
    "\n",
    "        Code to analyze:\n",
    "        ```\n",
    "        {code_block}\n",
    "        ```\n",
    "        \"\"\"\n",
    "\n",
    "        contents = [prompt]  # The LLM input is now a text prompt, not an image\n",
    "        response = model.generate_content(contents)\n",
    "\n",
    "        # TODO: Process the response and return the analysis and refined code\n",
    "        pass\n",
    "\n",
    "    except Exception as e:\n",
    "        raise gr.Error(f\"Error during analysis: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e40b837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 3: Suggesting bug fixes, improvements, or efficiency tweaks to the code snippet\n",
    "\n",
    "\"\"\"\n",
    "Example of running test cases on LLM-generated code.\n",
    "You do not need to follow this exact implementation for your code.\n",
    "\"\"\"\n",
    "import json\n",
    "import importlib.util\n",
    "\n",
    "def run_tests(filename_original, function_name, json_test_path):\n",
    "    # Load test cases\n",
    "    with open(json_test_path, 'r') as f:\n",
    "        test_cases = json.load(f)[\"test_case\"]\n",
    "\n",
    "    # Load the function from the file\n",
    "    spec = importlib.util.spec_from_file_location(function_name, filename_original)\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(module)\n",
    "    func = getattr(module, function_name)\n",
    "\n",
    "    # Run tests\n",
    "    for idx, case in enumerate(test_cases):\n",
    "        try:\n",
    "            inputs = case[\"input\"]\n",
    "            expected = case[\"expected\"]\n",
    "            result = func(*inputs) if isinstance(inputs, (list, tuple)) else func(inputs)\n",
    "            assert result == expected, f\"input={inputs}, expected={expected}, got={result}\"\n",
    "            print(f\"Test {idx+1} passed.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Test {idx+1} failed: {e}\")\n",
    "\n",
    "\"\"\"\n",
    "Make sure to save the final code (after transcribing and performing static analysis) into a Python file.\n",
    "For example, if you have saved the final code transcribed and fixed by the LLM as example_llm_code.py,\n",
    "you can run the test cases using the format below.\n",
    "\n",
    "You can also add more inputs and expected outputs to the JSON file to run additional tests.\n",
    "It is encouraged to add more test cases to ensure the robustness of your code.\n",
    "\"\"\"\n",
    "\n",
    "run_tests(\n",
    "    filename_original=\"example_llm_code.py\",\n",
    "    function_name=\"bucketsort\",\n",
    "    json_test_path=\"test_case_bucketsort.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ca5a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# PART 4: Implement the Gradio Interface to run the app\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
