{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a2d39d6",
   "metadata": {},
   "source": [
    "Team Members:\n",
    "- Emily Liang 79453973\n",
    "- Kristen Chung 42617410\n",
    "- \n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38d5258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "%pip install gradio unstructured sentence-transformers\n",
    "%pip install google.generativeai     # for using local IDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3e3fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# print(sys.executable)\n",
    "!{sys.executable} -m pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee59c4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries (RERUN THIS CELL IF NEEDED)\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "import google.generativeai as genai\n",
    "import gradio as gr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7385ca62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.generativeai import types #(RERUN THIS CELL IF NEEDED)\n",
    "import os\n",
    "\n",
    "# For local environment, directly put your API key here\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "genai.configure(api_key=api_key)\n",
    "model = genai.GenerativeModel(model_name=\"gemini-2.5-flash-lite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb0d3561",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1761896679.467766 4301318 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def flatten(arr):\n",
      "    for x in arr:\n",
      "        if isinstance(x, list):\n",
      "            for y in flatten(x):\n",
      "                yield y\n",
      "        else:\n",
      "            yield x\n"
     ]
    }
   ],
   "source": [
    "# PART 1: Transcribing handwritten Python code into a code snippet - Emily\n",
    "\n",
    "import re\n",
    "\n",
    "# Goal: take an img including handwritten python code, feed it into LLM, & return the python code as text\n",
    "def transcribe_image_code(image_file: Image.Image) -> str:\n",
    "    \"\"\"\n",
    "    Step 1: Transcribes code from the input image using a multimodal LLM.\n",
    "\n",
    "    Parameters:\n",
    "        image_file (Image.Image): The uploaded image containing handwritten code.\n",
    "\n",
    "    Returns:\n",
    "        str: The transcribed code as a string.\n",
    "    \"\"\"\n",
    "    \n",
    "    # prompt given to the LLM to transcribe the code from the image\n",
    "    prompt = \"\"\"Given the following image containing handwritten Python code, transcribe the code accurately into a text format and output it.\"\"\"\n",
    "\n",
    "    # call the LLM with the prompt and image\n",
    "    output = model.generate_content([prompt, image_file])\n",
    "\n",
    "    # extract the transcribed code from the LLM output & ensure it has text\n",
    "    code = output.text if output and output.text else \"\"\n",
    "\n",
    "    # remove any markdown formatting (like ```python ... ```) from the transcribed code\n",
    "    code = re.sub(r\"```(?:python)?\\n?\", \"\", code) \n",
    "    code = code.replace(\"```\", \"\")\n",
    "\n",
    "    # return the cleaned code as a string\n",
    "    return code.strip()\n",
    "\n",
    "# Testing the function with an example image\n",
    "img_path = \"code_images_example/code_image_07.jpg\"\n",
    "image = Image.open(img_path)\n",
    "print(transcribe_image_code(image))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a77e42b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. **What the code does:**\n",
      "This Python function `flatten` is intended to take a nested list (a list that may contain other lists within it) and return an iterator that yields all the non-list elements from the nested structure in a flattened manner. It uses recursion to traverse through the nested lists.\n",
      "\n",
      "2. **Syntax or logical bugs:**\n",
      "   - **Logical Bug 1: Infinite Recursion:** The most critical bug is in the `else` block: `yield flatten(x)`. When `x` is not a list, it's assumed to be a non-list element. However, the code incorrectly calls `flatten(x)` again. If `x` is an integer, for example, `flatten(x)` will raise a `TypeError` because `isinstance(x, list)` will be `False`, and then the code will attempt to iterate over `x` (which is an integer), leading to an infinite recursion or a `TypeError` depending on the exact type of `x`.\n",
      "   - **Logical Bug 2: Incorrect Yielding of Non-List Elements:** In the `else` block, instead of yielding the element `x` itself, it yields the *result* of `flatten(x)`, which is the generator itself. This means if `x` is a non-list element (like an integer), the generator would yield another generator, not the element.\n",
      "   - **Syntax Issue (Minor):** While not strictly a syntax error, the indentation of the `for y in flatten(x):` loop is incorrect. It's intended to be inside the `if isinstance(x, list):` block, but it's currently indented to be at the same level as the `if` statement, effectively outside of it.\n",
      "\n",
      "3. **Suggested fixes and efficiency improvements:**\n",
      "   - **Fix Bug 1 & 2:** In the `else` block, when `x` is not a list, we should simply `yield x` to return the element itself.\n",
      "   - **Fix Indentation:** Correct the indentation for the inner loop.\n",
      "   - **Efficiency (Generator):** The current use of `yield` makes it efficient by not loading the entire flattened list into memory at once. This is good and should be preserved.\n",
      "   - **Clarity:** Add a docstring to explain the function's purpose, arguments, and what it returns.\n",
      "\n",
      "4. **Refined version of the code:**\n",
      "See the `refined_code` section below.\n",
      "python\n",
      "def flatten(arr):\n",
      "    \"\"\"\n",
      "    Recursively flattens a nested list into an iterator.\n",
      "\n",
      "    Args:\n",
      "        arr: A list that may contain nested lists.\n",
      "\n",
      "    Yields:\n",
      "        The non-list elements from the nested structure.\n",
      "    \"\"\"\n",
      "    for x in arr:\n",
      "        if isinstance(x, list):\n",
      "            # If x is a list, recursively call flatten and yield each item\n",
      "            for y in flatten(x):\n",
      "                yield y\n",
      "        else:\n",
      "            # If x is not a list, yield x itself\n",
      "            yield x\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PART 2: Running static analysis and explaining bugs (if any) in natural language - Kristen\n",
    "import json\n",
    "import re\n",
    "import gradio as gr\n",
    "import google.generativeai as genai\n",
    "\n",
    "\n",
    "\n",
    "def analyze_code(code_block: str):\n",
    "    \"\"\"\n",
    "    Step 2: Performs static analysis on the transcribed code.\n",
    "\n",
    "    Parameters:\n",
    "        code_block (str): The transcribed code snippet.\n",
    "\n",
    "    Returns:\n",
    "        (1) The analysis text explaining bugs, improvements, or efficiency suggestions.\n",
    "        (2) The refined version of the code snippet with the suggested fixes and enhancements.\n",
    "    \"\"\"\n",
    "\n",
    "    if not code_block:\n",
    "        raise gr.Error(\"Please provide a valid code snippet.\")\n",
    "\n",
    "    try:\n",
    "        model = genai.GenerativeModel(model_name=\"gemini-2.5-flash-lite\")\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "        You are an expert Python developer and code reviewer.\n",
    "        Analyze the following code snippet and do the following:\n",
    "        1. Explain what the code does in natural language.\n",
    "        2. Identify any syntax or logical bugs.\n",
    "        3. Suggest specific fixes and efficiency improvements.\n",
    "        4. Provide a refined version of the code with your fixes applied.\n",
    "\n",
    "        Output your response in the following JSON format:\n",
    "        {{\n",
    "            \"analysis\": \"detailed explanation and improvements\",\n",
    "            \"refined_code\": \"refined Python code\"\n",
    "        }}\n",
    "\n",
    "        Code to analyze:\n",
    "        ```\n",
    "        {code_block}\n",
    "        ```\n",
    "        \"\"\"\n",
    "        response = model.generate_content(prompt)\n",
    "        text = (response.text or \"\").strip()\n",
    "\n",
    "\n",
    "        try:\n",
    "            data = json.loads(text)\n",
    "        \n",
    "        except json.JSONDecodeError:\n",
    "            # format \n",
    "            text = text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "            data = json.loads(text)\n",
    "\n",
    "        analysis = data.get(\"analysis\", \"No analysis found.\")\n",
    "        refined = data.get(\"refined_code\", code_block)\n",
    "\n",
    "        return analysis, refined\n",
    "\n",
    "    except Exception as e:\n",
    "        raise gr.Error(f\"Error during analysis: {e}\")\n",
    "\n",
    "# test call\n",
    "img_path = \"code_images_example/code_image_08.jpg\"\n",
    "image = Image.open(img_path)\n",
    "transcribed_code = transcribe_image_code(image)\n",
    "analysis, refined = analyze_code(transcribed_code)\n",
    "print(analysis)\n",
    "print(refined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e40b837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 3: Suggesting bug fixes, improvements, or efficiency tweaks to the code snippet\n",
    "\n",
    "\"\"\"\n",
    "Example of running test cases on LLM-generated code.\n",
    "You do not need to follow this exact implementation for your code.\n",
    "\"\"\"\n",
    "import json\n",
    "import importlib.util\n",
    "\n",
    "def run_tests(filename_original, function_name, json_test_path):\n",
    "    # Load test cases\n",
    "    with open(json_test_path, 'r') as f:\n",
    "        test_cases = json.load(f)[\"test_case\"]\n",
    "\n",
    "    # Load the function from the file\n",
    "    spec = importlib.util.spec_from_file_location(function_name, filename_original)\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(module)\n",
    "    func = getattr(module, function_name)\n",
    "\n",
    "    # Run tests\n",
    "    for idx, case in enumerate(test_cases):\n",
    "        try:\n",
    "            inputs = case[\"input\"]\n",
    "            expected = case[\"expected\"]\n",
    "            result = func(*inputs) if isinstance(inputs, (list, tuple)) else func(inputs)\n",
    "            assert result == expected, f\"input={inputs}, expected={expected}, got={result}\"\n",
    "            print(f\"Test {idx+1} passed.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Test {idx+1} failed: {e}\")\n",
    "\n",
    "\"\"\"\n",
    "Make sure to save the final code (after transcribing and performing static analysis) into a Python file.\n",
    "For example, if you have saved the final code transcribed and fixed by the LLM as example_llm_code.py,\n",
    "you can run the test cases using the format below.\n",
    "\n",
    "You can also add more inputs and expected outputs to the JSON file to run additional tests.\n",
    "It is encouraged to add more test cases to ensure the robustness of your code.\n",
    "\"\"\"\n",
    "\n",
    "run_tests(\n",
    "    filename_original=\"example_llm_code.py\",\n",
    "    function_name=\"bucketsort\",\n",
    "    json_test_path=\"test_case_bucketsort.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ca5a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# PART 4: Implement the Gradio Interface to run the app\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
