{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a2d39d6",
   "metadata": {},
   "source": [
    "Team Members:\n",
    "- Emily Liang 79453973\n",
    "- Kristen Chung 42617410\n",
    "- Kaomi Booker 85786904 \n",
    "- Angie Xetey 44067973"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38d5258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "%pip install gradio unstructured sentence-transformers\n",
    "%pip install google.generativeai     # for using local IDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3e3fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# print(sys.executable)\n",
    "!{sys.executable} -m pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee59c4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries (RERUN THIS CELL IF NEEDED)\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "import google.generativeai as genai\n",
    "import gradio as gr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7385ca62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.generativeai import types #(RERUN THIS CELL IF NEEDED)\n",
    "import os\n",
    "\n",
    "# For local environment, directly put your API key here\n",
    "api_key = os.getenv(\"AIzaSyBXfUMnHzX0lOOURTu54xZNYFXozuKLtRU\")\n",
    "genai.configure(api_key=api_key)\n",
    "model = genai.GenerativeModel(model_name=\"gemini-2.5-flash-lite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0d3561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 1: Transcribing handwritten Python code into a code snippet - Emily\n",
    "\n",
    "import re\n",
    "\n",
    "# Goal: take an img including handwritten python code, feed it into LLM, & return the python code as text\n",
    "def transcribe_image_code(image_file: Image.Image) -> str:\n",
    "    \"\"\"\n",
    "    Step 1: Transcribes code from the input image using a multimodal LLM.\n",
    "\n",
    "    Parameters:\n",
    "        image_file (Image.Image): The uploaded image containing handwritten code.\n",
    "\n",
    "    Returns:\n",
    "        str: The transcribed code as a string.\n",
    "    \"\"\"\n",
    "    \n",
    "    # prompt given to the LLM to transcribe the code from the image\n",
    "    prompt = \"\"\"Given the following image containing handwritten Python code, transcribe the code accurately into a text format and output it.\"\"\"\n",
    "\n",
    "    # call the LLM with the prompt and image\n",
    "    output = model.generate_content([prompt, image_file])\n",
    "\n",
    "    # extract the transcribed code from the LLM output & ensure it has text\n",
    "    code = output.text if output and output.text else \"\"\n",
    "\n",
    "    # remove any markdown formatting (like ```python ... ```) from the transcribed code\n",
    "    code = re.sub(r\"```(?:python)?\\n?\", \"\", code) \n",
    "    code = code.replace(\"```\", \"\")\n",
    "\n",
    "    # return the cleaned code as a string\n",
    "    return code.strip()\n",
    "\n",
    "# Testing the function with an example image\n",
    "img_path = \"code_images_example/code_image_07.jpg\"\n",
    "image = Image.open(img_path)\n",
    "print(transcribe_image_code(image))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77e42b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 2: Running static analysis and explaining bugs (if any) in natural language - Kristen\n",
    "import json\n",
    "import re\n",
    "import gradio as gr\n",
    "import google.generativeai as genai\n",
    "\n",
    "\n",
    "\n",
    "def analyze_code(code_block: str):\n",
    "    \"\"\"\n",
    "    Step 2: Performs static analysis on the transcribed code.\n",
    "\n",
    "    Parameters:\n",
    "        code_block (str): The transcribed code snippet.\n",
    "\n",
    "    Returns:\n",
    "        (1) The analysis text explaining bugs, improvements, or efficiency suggestions.\n",
    "        (2) The refined version of the code snippet with the suggested fixes and enhancements.\n",
    "    \"\"\"\n",
    "\n",
    "    if not code_block:\n",
    "        raise gr.Error(\"Please provide a valid code snippet.\")\n",
    "\n",
    "    try:\n",
    "        model = genai.GenerativeModel(model_name=\"gemini-2.5-flash-lite\")\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "        You are an expert Python developer and code reviewer.\n",
    "        Analyze the following code snippet and do the following:\n",
    "        1. Explain what the code does in natural language.\n",
    "        2. Identify any syntax or logical bugs.\n",
    "        3. Suggest specific fixes and efficiency improvements.\n",
    "        4. Provide a refined version of the code with your fixes applied.\n",
    "\n",
    "        Output your response in the following JSON format:\n",
    "        {{\n",
    "            \"analysis\": \"detailed explanation and improvements\",\n",
    "            \"refined_code\": \"refined Python code\"\n",
    "        }}\n",
    "\n",
    "        Code to analyze:\n",
    "        ```\n",
    "        {code_block}\n",
    "        ```\n",
    "        \"\"\"\n",
    "        response = model.generate_content(prompt)\n",
    "        text = (response.text or \"\").strip()\n",
    "\n",
    "\n",
    "        try:\n",
    "            data = json.loads(text)\n",
    "        \n",
    "        except json.JSONDecodeError:\n",
    "            # format \n",
    "            text = text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "            data = json.loads(text)\n",
    "\n",
    "        analysis = data.get(\"analysis\", \"No analysis found.\")\n",
    "        refined = data.get(\"refined_code\", code_block)\n",
    "\n",
    "        return analysis, refined\n",
    "\n",
    "    except Exception as e:\n",
    "        raise gr.Error(f\"Error during analysis: {e}\")\n",
    "\n",
    "# test call\n",
    "img_path = \"code_images_example/code_image_08.jpg\"\n",
    "image = Image.open(img_path)\n",
    "transcribed_code = transcribe_image_code(image)\n",
    "analysis, refined = analyze_code(transcribed_code)\n",
    "print(analysis)\n",
    "print(refined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e40b837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 3: Suggesting bug fixes, improvements, or efficiency tweaks to the code snippet\n",
    "\n",
    "import json\n",
    "import importlib.util\n",
    "from inspect import isgenerator\n",
    "\n",
    "# Map function names to their test JSON files\n",
    "FUNCTION_TEST_FILES = {\n",
    "    \"bucketsort\": \"test_case_bucketsort.json\",\n",
    "    \"flatten\": \"test_case_flatten.json\",\n",
    "    \"find_in_sorted\": \"test_case_find_in_sorted.json\",\n",
    "    \"pascal\": \"test_case_pascal.json\",\n",
    "    \"possible_change\": \"test_case_possible_change.json\"\n",
    "}\n",
    "\n",
    "def run_tests(filename_original, function_name, json_test_path):\n",
    "    \"\"\"Run test cases on a function from a Python file.\"\"\"\n",
    "    with open(json_test_path, 'r') as f:\n",
    "        test_cases = json.load(f)[\"test_case\"]\n",
    "\n",
    "    spec = importlib.util.spec_from_file_location(function_name, filename_original)\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(module)\n",
    "    func = getattr(module, function_name)\n",
    "\n",
    "    results = {\"passed\": 0, \"failed\": 0, \"errors\": []}\n",
    "    \n",
    "    for idx, case in enumerate(test_cases):\n",
    "        try:\n",
    "            inputs = case[\"input\"]\n",
    "            expected = case[\"expected\"]\n",
    "            result = func(*inputs) if isinstance(inputs, (list, tuple)) else func(inputs)\n",
    "            \n",
    "            # Convert generator to list if needed\n",
    "            if isgenerator(result):\n",
    "                result = list(result)\n",
    "            \n",
    "            assert result == expected, f\"input={inputs}, expected={expected}, got={result}\"\n",
    "            print(f\"Test {idx+1} passed.\")\n",
    "            results[\"passed\"] += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Test {idx+1} failed: {e}\")\n",
    "            results[\"failed\"] += 1\n",
    "            results[\"errors\"].append(f\"Test {idx+1}: {str(e)}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def save_refined_code(refined_code_str: str, output_filename: str = \"refined_code.py\"):\n",
    "    \"\"\"Save refined code string to a Python file.\"\"\"\n",
    "    with open(output_filename, 'w') as f:\n",
    "        f.write(refined_code_str)\n",
    "    print(f\"Refined code saved to {output_filename}\")\n",
    "    return output_filename\n",
    "\n",
    "def test_refined_function(refined_code_str: str, function_name: str, output_filename: str = None):\n",
    "    \"\"\"Save refined code and test it automatically using the correct test file.\"\"\"\n",
    "    if output_filename is None:\n",
    "        output_filename = f\"{function_name}_refined.py\"\n",
    "    \n",
    "    # Check if test file exists for this function\n",
    "    if function_name not in FUNCTION_TEST_FILES:\n",
    "        print(f\"Warning: No test file found for function '{function_name}'\")\n",
    "        print(f\"Available functions: {list(FUNCTION_TEST_FILES.keys())}\")\n",
    "        return {\"passed\": 0, \"failed\": 0, \"errors\": [f\"Function '{function_name}' not in test configuration\"]}\n",
    "    \n",
    "    json_test_path = FUNCTION_TEST_FILES[function_name]\n",
    "    \n",
    "    # Save the refined code\n",
    "    saved_file = save_refined_code(refined_code_str, output_filename)\n",
    "    \n",
    "    # Run tests and return results\n",
    "    print(f\"\\nTesting {function_name} with {json_test_path}:\")\n",
    "    print(\"-\" * 50)\n",
    "    return run_tests(saved_file, function_name, json_test_path)\n",
    "\n",
    "def test_multiple_functions(function_tests: dict):\n",
    "    \"\"\"Test multiple functions at once. Takes dict of {function_name: test_file}.\"\"\"\n",
    "    all_results = {}\n",
    "    \n",
    "    for function_name, json_test_path in function_tests.items():\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Testing {function_name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Try to find the file - could be function_name.py or function_name_refined.py\n",
    "        possible_files = [f\"{function_name}.py\", f\"{function_name}_refined.py\", \"example_llm_code.py\"]\n",
    "        found_file = None\n",
    "        \n",
    "        for filename in possible_files:\n",
    "            try:\n",
    "                with open(filename, 'r'):\n",
    "                    found_file = filename\n",
    "                    break\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "        \n",
    "        if found_file:\n",
    "            results = run_tests(found_file, function_name, json_test_path)\n",
    "            all_results[function_name] = results\n",
    "        else:\n",
    "            print(f\"Warning: Could not find a file containing {function_name}\")\n",
    "            print(f\"  Tried: {possible_files}\")\n",
    "            all_results[function_name] = {\"passed\": 0, \"failed\": 0, \"errors\": [\"File not found\"]}\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"SUMMARY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    for func_name, results in all_results.items():\n",
    "        passed = results.get(\"passed\", 0)\n",
    "        failed = results.get(\"failed\", 0)\n",
    "        total = passed + failed\n",
    "        print(f\"{func_name}: {passed}/{total} tests passed\")\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "# Example usage: Test refined code from Part 2\n",
    "if 'refined' in globals():\n",
    "    test_refined_function(refined, \"flatten\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0ca5a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* Running on public URL: https://075d6fa2481d345347.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://075d6fa2481d345347.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# PART 4: Implement the Gradio Interface to run the app - Angie & \n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "## TODO: Implement the Gradio Interface to run the app\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeafa28c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
