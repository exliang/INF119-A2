{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a2d39d6",
   "metadata": {},
   "source": [
    "Team Members:\n",
    "- Emily Liang 79453973\n",
    "- \n",
    "- \n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38d5258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "%pip install gradio unstructured sentence-transformers\n",
    "%pip install google.generativeai     # for using local IDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3e3fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# print(sys.executable)\n",
    "!{sys.executable} -m pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee59c4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7385ca62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.generativeai import types\n",
    "import os\n",
    "\n",
    "# For local environment, directly put your API key here\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "genai.configure(api_key=api_key)\n",
    "client = genai.GenerativeModel(model_name=\"gemini-2.5-flash-lite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0d3561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 1: Transcribing handwritten Python code into a code snippet\n",
    "\n",
    "\"\"\"\n",
    "Note: This template serves as a starting point.\n",
    "You are expected to modify and extend the code to fulfill the assignment requirements.\n",
    "\"\"\"\n",
    "\n",
    "def transcribe_image_code(image_file: Image.Image) -> str:\n",
    "    \"\"\"\n",
    "    Step 1: Transcribes code from the input image using a multimodal LLM.\n",
    "\n",
    "    Parameters:\n",
    "        image_file (Image.Image): The uploaded image containing handwritten code.\n",
    "\n",
    "    Returns:\n",
    "        str: The transcribed code as a string.\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Implement your code transcription logic here\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77e42b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 2: Running static analysis and explaining bugs (if any) in natural language\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "def analyze_code(code_block: str):\n",
    "    \"\"\"\n",
    "    Step 2: Performs static analysis on the transcribed code.\n",
    "\n",
    "    Parameters:\n",
    "        code_block (str): The transcribed code snippet.\n",
    "\n",
    "    Returns:\n",
    "        (1) The analysis text explaining bugs, improvements, or efficiency suggestions.\n",
    "        (2) The refined version of the code snippet with the suggested fixes and enhancements.\n",
    "    \"\"\"\n",
    "\n",
    "    if not code_block:\n",
    "        raise gr.Error(\"Please provide a valid code snippet.\")\n",
    "\n",
    "    try:\n",
    "        model = genai.GenerativeModel(MODEL_ID)\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "        You are an expert Python developer and code reviewer. Analyze the following code.\n",
    "\n",
    "        ## TODO: Modify the prompt to inference LLM on the code snippet.\n",
    "\n",
    "        Code to analyze:\n",
    "        ```\n",
    "        {code_block}\n",
    "        ```\n",
    "        \"\"\"\n",
    "\n",
    "        contents = [prompt]  # The LLM input is now a text prompt, not an image\n",
    "        response = model.generate_content(contents)\n",
    "\n",
    "        # TODO: Process the response and return the analysis and refined code\n",
    "        pass\n",
    "\n",
    "    except Exception as e:\n",
    "        raise gr.Error(f\"Error during analysis: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e40b837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 3: Suggesting bug fixes, improvements, or efficiency tweaks to the code snippet\n",
    "\n",
    "\"\"\"\n",
    "Example of running test cases on LLM-generated code.\n",
    "You do not need to follow this exact implementation for your code.\n",
    "\"\"\"\n",
    "import json\n",
    "import importlib.util\n",
    "\n",
    "def run_tests(filename_original, function_name, json_test_path):\n",
    "    # Load test cases\n",
    "    with open(json_test_path, 'r') as f:\n",
    "        test_cases = json.load(f)[\"test_case\"]\n",
    "\n",
    "    # Load the function from the file\n",
    "    spec = importlib.util.spec_from_file_location(function_name, filename_original)\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(module)\n",
    "    func = getattr(module, function_name)\n",
    "\n",
    "    # Run tests\n",
    "    for idx, case in enumerate(test_cases):\n",
    "        try:\n",
    "            inputs = case[\"input\"]\n",
    "            expected = case[\"expected\"]\n",
    "            result = func(*inputs) if isinstance(inputs, (list, tuple)) else func(inputs)\n",
    "            assert result == expected, f\"input={inputs}, expected={expected}, got={result}\"\n",
    "            print(f\"Test {idx+1} passed.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Test {idx+1} failed: {e}\")\n",
    "\n",
    "\"\"\"\n",
    "Make sure to save the final code (after transcribing and performing static analysis) into a Python file.\n",
    "For example, if you have saved the final code transcribed and fixed by the LLM as example_llm_code.py,\n",
    "you can run the test cases using the format below.\n",
    "\n",
    "You can also add more inputs and expected outputs to the JSON file to run additional tests.\n",
    "It is encouraged to add more test cases to ensure the robustness of your code.\n",
    "\"\"\"\n",
    "\n",
    "run_tests(\n",
    "    filename_original=\"example_llm_code.py\",\n",
    "    function_name=\"bucketsort\",\n",
    "    json_test_path=\"test_case_bucketsort.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ca5a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# PART 4: Implement the Gradio Interface to run the app\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
